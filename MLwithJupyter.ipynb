{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "305f3d0d",
   "metadata": {},
   "source": [
    "# FIT1043"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a60a5a",
   "metadata": {},
   "source": [
    "## Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a8aa2",
   "metadata": {},
   "source": [
    "Name: Joshua Lim Boon Hor\n",
    "Student ID: 32633122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a4432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b7fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb22e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a1ffa98",
   "metadata": {},
   "source": [
    "## 1. Assignment Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89bb9cc",
   "metadata": {},
   "source": [
    "### 1.a. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f87fb7",
   "metadata": {},
   "source": [
    "Section 1 of the assignemnt focuses on analysing the data retrieved from the essay features csv file and providing some description of said data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a983f7",
   "metadata": {},
   "source": [
    "### 1.a1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9474a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score as cks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c028c5",
   "metadata": {},
   "source": [
    "### 1.a2. Reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786177e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('FIT1043-Essay-Features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f84aca",
   "metadata": {},
   "source": [
    ".shape will show how many rows and columns there are in the dataset respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef729de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1332, 19)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1332, 19)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec0585a",
   "metadata": {},
   "source": [
    "### 1.b. Datatypes in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6834f3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essayid                        int64\n",
       "chars                          int64\n",
       "words                          int64\n",
       "commas                         int64\n",
       "apostrophes                    int64\n",
       "punctuations                   int64\n",
       "avg_word_length              float64\n",
       "sentences                      int64\n",
       "questions                      int64\n",
       "avg_word_sentence            float64\n",
       "POS                          float64\n",
       "POS/total_words              float64\n",
       "prompt_words                   int64\n",
       "prompt_words/total_words     float64\n",
       "synonym_words                  int64\n",
       "synonym_words/total_words    float64\n",
       "unstemmed                      int64\n",
       "stemmed                        int64\n",
       "score                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "essayid                        int64\n",
       "chars                          int64\n",
       "words                          int64\n",
       "commas                         int64\n",
       "apostrophes                    int64\n",
       "punctuations                   int64\n",
       "avg_word_length              float64\n",
       "sentences                      int64\n",
       "questions                      int64\n",
       "avg_word_sentence            float64\n",
       "POS                          float64\n",
       "POS/total_words              float64\n",
       "prompt_words                   int64\n",
       "prompt_words/total_words     float64\n",
       "synonym_words                  int64\n",
       "synonym_words/total_words    float64\n",
       "unstemmed                      int64\n",
       "stemmed                        int64\n",
       "score                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc70785a",
   "metadata": {},
   "source": [
    "#### A small test to see if the values have been read correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8017c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1151</td>\n",
       "      <td>2404</td>\n",
       "      <td>467</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5.147752</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>21.227273</td>\n",
       "      <td>462.987069</td>\n",
       "      <td>0.991407</td>\n",
       "      <td>200</td>\n",
       "      <td>0.428266</td>\n",
       "      <td>113</td>\n",
       "      <td>0.241970</td>\n",
       "      <td>529</td>\n",
       "      <td>519</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1015</td>\n",
       "      <td>1182</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4.904564</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>238.655462</td>\n",
       "      <td>0.990272</td>\n",
       "      <td>94</td>\n",
       "      <td>0.390041</td>\n",
       "      <td>67</td>\n",
       "      <td>0.278008</td>\n",
       "      <td>293</td>\n",
       "      <td>283</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>1345</td>\n",
       "      <td>1814</td>\n",
       "      <td>363</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.997245</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>27.923077</td>\n",
       "      <td>362.329640</td>\n",
       "      <td>0.998153</td>\n",
       "      <td>170</td>\n",
       "      <td>0.468320</td>\n",
       "      <td>107</td>\n",
       "      <td>0.294766</td>\n",
       "      <td>427</td>\n",
       "      <td>415</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>344</td>\n",
       "      <td>1427</td>\n",
       "      <td>287</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.972125</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>22.076923</td>\n",
       "      <td>284.657277</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>144</td>\n",
       "      <td>0.501742</td>\n",
       "      <td>83</td>\n",
       "      <td>0.289199</td>\n",
       "      <td>323</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1077</td>\n",
       "      <td>2806</td>\n",
       "      <td>542</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.177122</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>24.636364</td>\n",
       "      <td>538.988889</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>284</td>\n",
       "      <td>0.523985</td>\n",
       "      <td>155</td>\n",
       "      <td>0.285978</td>\n",
       "      <td>596</td>\n",
       "      <td>575</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essayid  chars  words  commas  apostrophes  punctuations  \\\n",
       "1327     1151   2404    467      16           10             0   \n",
       "1328     1015   1182    241       0           14             0   \n",
       "1329     1345   1814    363       5           11             0   \n",
       "1330      344   1427    287       5            8             0   \n",
       "1331     1077   2806    542      24            6             0   \n",
       "\n",
       "      avg_word_length  sentences  questions  avg_word_sentence         POS  \\\n",
       "1327         5.147752         22          0          21.227273  462.987069   \n",
       "1328         4.904564         16          0          15.062500  238.655462   \n",
       "1329         4.997245         13          3          27.923077  362.329640   \n",
       "1330         4.972125         13          1          22.076923  284.657277   \n",
       "1331         5.177122         22          3          24.636364  538.988889   \n",
       "\n",
       "      POS/total_words  prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "1327         0.991407           200                  0.428266            113   \n",
       "1328         0.990272            94                  0.390041             67   \n",
       "1329         0.998153           170                  0.468320            107   \n",
       "1330         0.991837           144                  0.501742             83   \n",
       "1331         0.994444           284                  0.523985            155   \n",
       "\n",
       "      synonym_words/total_words  unstemmed  stemmed  score  \n",
       "1327                   0.241970        529      519      4  \n",
       "1328                   0.278008        293      283      3  \n",
       "1329                   0.294766        427      415      3  \n",
       "1330                   0.289199        323      312      3  \n",
       "1331                   0.285978        596      575      4  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1151</td>\n",
       "      <td>2404</td>\n",
       "      <td>467</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5.147752</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>21.227273</td>\n",
       "      <td>462.987069</td>\n",
       "      <td>0.991407</td>\n",
       "      <td>200</td>\n",
       "      <td>0.428266</td>\n",
       "      <td>113</td>\n",
       "      <td>0.241970</td>\n",
       "      <td>529</td>\n",
       "      <td>519</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1015</td>\n",
       "      <td>1182</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4.904564</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>238.655462</td>\n",
       "      <td>0.990272</td>\n",
       "      <td>94</td>\n",
       "      <td>0.390041</td>\n",
       "      <td>67</td>\n",
       "      <td>0.278008</td>\n",
       "      <td>293</td>\n",
       "      <td>283</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>1345</td>\n",
       "      <td>1814</td>\n",
       "      <td>363</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.997245</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>27.923077</td>\n",
       "      <td>362.329640</td>\n",
       "      <td>0.998153</td>\n",
       "      <td>170</td>\n",
       "      <td>0.468320</td>\n",
       "      <td>107</td>\n",
       "      <td>0.294766</td>\n",
       "      <td>427</td>\n",
       "      <td>415</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>344</td>\n",
       "      <td>1427</td>\n",
       "      <td>287</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.972125</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>22.076923</td>\n",
       "      <td>284.657277</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>144</td>\n",
       "      <td>0.501742</td>\n",
       "      <td>83</td>\n",
       "      <td>0.289199</td>\n",
       "      <td>323</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1077</td>\n",
       "      <td>2806</td>\n",
       "      <td>542</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.177122</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>24.636364</td>\n",
       "      <td>538.988889</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>284</td>\n",
       "      <td>0.523985</td>\n",
       "      <td>155</td>\n",
       "      <td>0.285978</td>\n",
       "      <td>596</td>\n",
       "      <td>575</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essayid  chars  words  commas  apostrophes  punctuations  \\\n",
       "1327     1151   2404    467      16           10             0   \n",
       "1328     1015   1182    241       0           14             0   \n",
       "1329     1345   1814    363       5           11             0   \n",
       "1330      344   1427    287       5            8             0   \n",
       "1331     1077   2806    542      24            6             0   \n",
       "\n",
       "      avg_word_length  sentences  questions  avg_word_sentence         POS  \\\n",
       "1327         5.147752         22          0          21.227273  462.987069   \n",
       "1328         4.904564         16          0          15.062500  238.655462   \n",
       "1329         4.997245         13          3          27.923077  362.329640   \n",
       "1330         4.972125         13          1          22.076923  284.657277   \n",
       "1331         5.177122         22          3          24.636364  538.988889   \n",
       "\n",
       "      POS/total_words  prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "1327         0.991407           200                  0.428266            113   \n",
       "1328         0.990272            94                  0.390041             67   \n",
       "1329         0.998153           170                  0.468320            107   \n",
       "1330         0.991837           144                  0.501742             83   \n",
       "1331         0.994444           284                  0.523985            155   \n",
       "\n",
       "      synonym_words/total_words  unstemmed  stemmed  score  \n",
       "1327                   0.241970        529      519      4  \n",
       "1328                   0.278008        293      283      3  \n",
       "1329                   0.294766        427      415      3  \n",
       "1330                   0.289199        323      312      3  \n",
       "1331                   0.285978        596      575      4  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a571c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1457</td>\n",
       "      <td>2153</td>\n",
       "      <td>426</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.053991</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>26.625000</td>\n",
       "      <td>423.995272</td>\n",
       "      <td>0.995294</td>\n",
       "      <td>207</td>\n",
       "      <td>0.485915</td>\n",
       "      <td>105</td>\n",
       "      <td>0.246479</td>\n",
       "      <td>424</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>503</td>\n",
       "      <td>1480</td>\n",
       "      <td>292</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.068493</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>26.545455</td>\n",
       "      <td>290.993103</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>148</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>77</td>\n",
       "      <td>0.263699</td>\n",
       "      <td>356</td>\n",
       "      <td>345</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253</td>\n",
       "      <td>3964</td>\n",
       "      <td>849</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4.669022</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>17.326531</td>\n",
       "      <td>843.990544</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>285</td>\n",
       "      <td>0.335689</td>\n",
       "      <td>130</td>\n",
       "      <td>0.153121</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>988</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.704762</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>207.653784</td>\n",
       "      <td>0.988828</td>\n",
       "      <td>112</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>62</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>217</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1450</td>\n",
       "      <td>3139</td>\n",
       "      <td>600</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5.231667</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>594.652150</td>\n",
       "      <td>0.991087</td>\n",
       "      <td>255</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>165</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>702</td>\n",
       "      <td>677</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essayid  chars  words  commas  apostrophes  punctuations  avg_word_length  \\\n",
       "0     1457   2153    426      14            6             0         5.053991   \n",
       "1      503   1480    292       9            7             0         5.068493   \n",
       "2      253   3964    849      19           26             1         4.669022   \n",
       "3      107    988    210       8            7             0         4.704762   \n",
       "4     1450   3139    600      13            8             0         5.231667   \n",
       "\n",
       "   sentences  questions  avg_word_sentence         POS  POS/total_words  \\\n",
       "0         16          0          26.625000  423.995272         0.995294   \n",
       "1         11          0          26.545455  290.993103         0.996552   \n",
       "2         49          2          17.326531  843.990544         0.994100   \n",
       "3         12          0          17.500000  207.653784         0.988828   \n",
       "4         24          1          25.000000  594.652150         0.991087   \n",
       "\n",
       "   prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0           207                  0.485915            105   \n",
       "1           148                  0.506849             77   \n",
       "2           285                  0.335689            130   \n",
       "3           112                  0.533333             62   \n",
       "4           255                  0.425000            165   \n",
       "\n",
       "   synonym_words/total_words  unstemmed  stemmed  score  \n",
       "0                   0.246479        424      412      4  \n",
       "1                   0.263699        356      345      4  \n",
       "2                   0.153121        750      750      4  \n",
       "3                   0.295238        217      209      3  \n",
       "4                   0.275000        702      677      4  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1457</td>\n",
       "      <td>2153</td>\n",
       "      <td>426</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.053991</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>26.625000</td>\n",
       "      <td>423.995272</td>\n",
       "      <td>0.995294</td>\n",
       "      <td>207</td>\n",
       "      <td>0.485915</td>\n",
       "      <td>105</td>\n",
       "      <td>0.246479</td>\n",
       "      <td>424</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>503</td>\n",
       "      <td>1480</td>\n",
       "      <td>292</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.068493</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>26.545455</td>\n",
       "      <td>290.993103</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>148</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>77</td>\n",
       "      <td>0.263699</td>\n",
       "      <td>356</td>\n",
       "      <td>345</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253</td>\n",
       "      <td>3964</td>\n",
       "      <td>849</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4.669022</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>17.326531</td>\n",
       "      <td>843.990544</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>285</td>\n",
       "      <td>0.335689</td>\n",
       "      <td>130</td>\n",
       "      <td>0.153121</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>988</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.704762</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>207.653784</td>\n",
       "      <td>0.988828</td>\n",
       "      <td>112</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>62</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>217</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1450</td>\n",
       "      <td>3139</td>\n",
       "      <td>600</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5.231667</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>594.652150</td>\n",
       "      <td>0.991087</td>\n",
       "      <td>255</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>165</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>702</td>\n",
       "      <td>677</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essayid  chars  words  commas  apostrophes  punctuations  avg_word_length  \\\n",
       "0     1457   2153    426      14            6             0         5.053991   \n",
       "1      503   1480    292       9            7             0         5.068493   \n",
       "2      253   3964    849      19           26             1         4.669022   \n",
       "3      107    988    210       8            7             0         4.704762   \n",
       "4     1450   3139    600      13            8             0         5.231667   \n",
       "\n",
       "   sentences  questions  avg_word_sentence         POS  POS/total_words  \\\n",
       "0         16          0          26.625000  423.995272         0.995294   \n",
       "1         11          0          26.545455  290.993103         0.996552   \n",
       "2         49          2          17.326531  843.990544         0.994100   \n",
       "3         12          0          17.500000  207.653784         0.988828   \n",
       "4         24          1          25.000000  594.652150         0.991087   \n",
       "\n",
       "   prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0           207                  0.485915            105   \n",
       "1           148                  0.506849             77   \n",
       "2           285                  0.335689            130   \n",
       "3           112                  0.533333             62   \n",
       "4           255                  0.425000            165   \n",
       "\n",
       "   synonym_words/total_words  unstemmed  stemmed  score  \n",
       "0                   0.246479        424      412      4  \n",
       "1                   0.263699        356      345      4  \n",
       "2                   0.153121        750      750      4  \n",
       "3                   0.295238        217      209      3  \n",
       "4                   0.275000        702      677      4  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46342c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>1075</td>\n",
       "      <td>1870</td>\n",
       "      <td>371</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.040431</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>16.863636</td>\n",
       "      <td>367.324251</td>\n",
       "      <td>0.990092</td>\n",
       "      <td>192</td>\n",
       "      <td>0.517520</td>\n",
       "      <td>94</td>\n",
       "      <td>0.253369</td>\n",
       "      <td>404</td>\n",
       "      <td>389</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1499</td>\n",
       "      <td>2275</td>\n",
       "      <td>466</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.881974</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>24.526316</td>\n",
       "      <td>459.317426</td>\n",
       "      <td>0.985660</td>\n",
       "      <td>246</td>\n",
       "      <td>0.527897</td>\n",
       "      <td>120</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>510</td>\n",
       "      <td>489</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>416</td>\n",
       "      <td>2697</td>\n",
       "      <td>512</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5.267578</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>507.649673</td>\n",
       "      <td>0.991503</td>\n",
       "      <td>266</td>\n",
       "      <td>0.519531</td>\n",
       "      <td>135</td>\n",
       "      <td>0.263672</td>\n",
       "      <td>582</td>\n",
       "      <td>567</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>750</td>\n",
       "      <td>2238</td>\n",
       "      <td>436</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.133028</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>432.660494</td>\n",
       "      <td>0.992341</td>\n",
       "      <td>193</td>\n",
       "      <td>0.442661</td>\n",
       "      <td>107</td>\n",
       "      <td>0.245413</td>\n",
       "      <td>557</td>\n",
       "      <td>547</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>988</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.704762</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>207.653784</td>\n",
       "      <td>0.988828</td>\n",
       "      <td>112</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>62</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>217</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essayid  chars  words  commas  apostrophes  punctuations  \\\n",
       "1157     1075   1870    371      21            3             0   \n",
       "419      1499   2275    466       4           11             0   \n",
       "1218      416   2697    512      22           15             0   \n",
       "1240      750   2238    436       9            2             1   \n",
       "3         107    988    210       8            7             0   \n",
       "\n",
       "      avg_word_length  sentences  questions  avg_word_sentence         POS  \\\n",
       "1157         5.040431         22          0          16.863636  367.324251   \n",
       "419          4.881974         19          2          24.526316  459.317426   \n",
       "1218         5.267578         28          2          18.285714  507.649673   \n",
       "1240         5.133028         20          0          21.800000  432.660494   \n",
       "3            4.704762         12          0          17.500000  207.653784   \n",
       "\n",
       "      POS/total_words  prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "1157         0.990092           192                  0.517520             94   \n",
       "419          0.985660           246                  0.527897            120   \n",
       "1218         0.991503           266                  0.519531            135   \n",
       "1240         0.992341           193                  0.442661            107   \n",
       "3            0.988828           112                  0.533333             62   \n",
       "\n",
       "      synonym_words/total_words  unstemmed  stemmed  score  \n",
       "1157                   0.253369        404      389      4  \n",
       "419                    0.257511        510      489      3  \n",
       "1218                   0.263672        582      567      3  \n",
       "1240                   0.245413        557      547      4  \n",
       "3                      0.295238        217      209      3  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>1075</td>\n",
       "      <td>1870</td>\n",
       "      <td>371</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.040431</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>16.863636</td>\n",
       "      <td>367.324251</td>\n",
       "      <td>0.990092</td>\n",
       "      <td>192</td>\n",
       "      <td>0.517520</td>\n",
       "      <td>94</td>\n",
       "      <td>0.253369</td>\n",
       "      <td>404</td>\n",
       "      <td>389</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1499</td>\n",
       "      <td>2275</td>\n",
       "      <td>466</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.881974</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>24.526316</td>\n",
       "      <td>459.317426</td>\n",
       "      <td>0.985660</td>\n",
       "      <td>246</td>\n",
       "      <td>0.527897</td>\n",
       "      <td>120</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>510</td>\n",
       "      <td>489</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>416</td>\n",
       "      <td>2697</td>\n",
       "      <td>512</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5.267578</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>507.649673</td>\n",
       "      <td>0.991503</td>\n",
       "      <td>266</td>\n",
       "      <td>0.519531</td>\n",
       "      <td>135</td>\n",
       "      <td>0.263672</td>\n",
       "      <td>582</td>\n",
       "      <td>567</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>750</td>\n",
       "      <td>2238</td>\n",
       "      <td>436</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.133028</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>432.660494</td>\n",
       "      <td>0.992341</td>\n",
       "      <td>193</td>\n",
       "      <td>0.442661</td>\n",
       "      <td>107</td>\n",
       "      <td>0.245413</td>\n",
       "      <td>557</td>\n",
       "      <td>547</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>988</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.704762</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>207.653784</td>\n",
       "      <td>0.988828</td>\n",
       "      <td>112</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>62</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>217</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essayid  chars  words  commas  apostrophes  punctuations  \\\n",
       "1157     1075   1870    371      21            3             0   \n",
       "419      1499   2275    466       4           11             0   \n",
       "1218      416   2697    512      22           15             0   \n",
       "1240      750   2238    436       9            2             1   \n",
       "3         107    988    210       8            7             0   \n",
       "\n",
       "      avg_word_length  sentences  questions  avg_word_sentence         POS  \\\n",
       "1157         5.040431         22          0          16.863636  367.324251   \n",
       "419          4.881974         19          2          24.526316  459.317426   \n",
       "1218         5.267578         28          2          18.285714  507.649673   \n",
       "1240         5.133028         20          0          21.800000  432.660494   \n",
       "3            4.704762         12          0          17.500000  207.653784   \n",
       "\n",
       "      POS/total_words  prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "1157         0.990092           192                  0.517520             94   \n",
       "419          0.985660           246                  0.527897            120   \n",
       "1218         0.991503           266                  0.519531            135   \n",
       "1240         0.992341           193                  0.442661            107   \n",
       "3            0.988828           112                  0.533333             62   \n",
       "\n",
       "      synonym_words/total_words  unstemmed  stemmed  score  \n",
       "1157                   0.253369        404      389      4  \n",
       "419                    0.257511        510      489      3  \n",
       "1218                   0.263672        582      567      3  \n",
       "1240                   0.245413        557      547      4  \n",
       "3                      0.295238        217      209      3  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b9bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b951427e",
   "metadata": {},
   "source": [
    "## 2. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581f448",
   "metadata": {},
   "source": [
    "### 2.a. Supervised Machine Learning, The Notion of Labelled Data and Training and Testing datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b0d34",
   "metadata": {},
   "source": [
    "Supervised learning is when we must create a predictive model based on the given output and input data. There are 2 proportions of data the higher proportion, that is used for training purposes, and the lower proportion, which is used for testing purposes. Later, the data retrieved from training is used to create a predictive model, which is then used to make predictions that are then compared with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c62c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c2fa156",
   "metadata": {},
   "source": [
    "### 2.b.  Separating the features and the labels \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885623c4",
   "metadata": {},
   "source": [
    "The label being used here is \"score\" as instructed by the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a2b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features.iloc[:,np.r_[1:5,7:9,13:18]].values #feature data\n",
    "y = features.iloc[:,18].values #labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89aa880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "637275b5",
   "metadata": {},
   "source": [
    "### 2.c. Splitting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc2112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58121ea2",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726cc602",
   "metadata": {},
   "source": [
    "### 3.a Explaining the difference between binary and multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da461db3",
   "metadata": {},
   "source": [
    "Binary classification are tasks where examples are assigned to exactly one of two classes. Whereas, Multi-class classificatioin are tasks when examples are assigned exactly one of more than two classes. Here we can see that we are doing Multi-class Classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3fc30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ddc3ff2",
   "metadata": {},
   "source": [
    "### 3.b In preparation for Support Vector Machine/Regression, your data should be normalised/scaled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae5a03",
   "metadata": {},
   "source": [
    "### 3.bi. Feature Scaling or Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6742166",
   "metadata": {},
   "source": [
    "Since we have a range of values that varies widely, in some machine learning algorithms,\n",
    "objective functions will cease to work properly without feature scaling (also known as normalization). For\n",
    "example, many people who classify, calculate the distance between two points using its Euclidean\n",
    "distance. If one of the features had a broader range of values, the distance would be influenced greatly by this particular feature. Therefore, by normalizing the features, we are able to ensure that each feature contributes proportionately to the final distance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda02f24",
   "metadata": {},
   "source": [
    "### 3.bii. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e498c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features\n",
    "scale = StandardScaler()\n",
    "x_train = scale.fit_transform(x_train)\n",
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a176df7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62c95a04",
   "metadata": {},
   "source": [
    "### 3.c Using the SVM algorithm to build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d74cc6",
   "metadata": {},
   "source": [
    "### 3.ci. Describing SVM in relation to Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c5950f",
   "metadata": {},
   "source": [
    "First of all before i start describing SVM in relation to Linear regression, I must first explain what SVM and Linear regression are respectively. \n",
    "\n",
    "The main point i would like to highlight is; \n",
    "\n",
    "Linear regression: gives explicit decisions\n",
    "SVM: finds an approximate of real decisions because of computational solutions.\n",
    "\n",
    "So, if SVM and Linear regression have this key difference how can they be used in relation? \n",
    "An SVM is a supervised algorithm that is used for both classification and regression tasks. It can solve linear and non-linear problems and work well for many practical problems. The algorithm basically creates a line or a hyperplane that will seperate the data into classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d86f7",
   "metadata": {},
   "source": [
    "### 3.cii. Explaining the kernel in SVM/SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b37ae6a",
   "metadata": {},
   "source": [
    "The main function of the kernel is to transform a given datasets input data into the required form. The types include, polynomial, radial basis and linear functions. Polynomial and RBF are useful for non-linear planes. Usually, the computational cost increases as the dimension of data increases which would occur when we required to move to a higher dimension but are unable to find a seperating hyperplane. However, A kernel reduces computational cost by helping find a hyperplane in the higher dimensional space without the need to increase computational cost. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2184995",
   "metadata": {},
   "source": [
    "### 3.ciii. Building the model using the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a615e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a svm classifier\n",
    "clf = svm.SVC(kernel = 'linear') #linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42bc0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model using the training sets\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e50549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "239c6bf4",
   "metadata": {},
   "source": [
    "### 3.d. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac2a1d8",
   "metadata": {},
   "source": [
    "### 3.di. Using the dataset in 2.ciii. we are conducting the prediction for the score label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1983f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, 2, 3, 4, 4, 4, 2, 4, 4, 3, 4, 3, 3, 4, 3, 4, 4, 4, 3, 3,\n",
       "       3, 3, 3, 4, 4, 4, 3, 4, 4, 3, 3, 4, 4, 3, 4, 4, 3, 3, 4, 2, 3, 3,\n",
       "       3, 3, 3, 3, 2, 3, 4, 3, 4, 4, 4, 4, 4, 3, 3, 4, 3, 4, 3, 3, 4, 4,\n",
       "       4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 4, 4, 3, 4, 3, 4, 3, 3, 4, 3, 2,\n",
       "       4, 4, 3, 4, 3, 3, 1, 3, 3, 4, 3, 2, 4, 3, 3, 4, 4, 2, 4, 4, 4, 4,\n",
       "       2, 3, 3, 4, 3, 4, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4,\n",
       "       4, 3, 4, 3, 3, 4, 4, 3, 4, 4, 4, 3, 3, 3, 3, 3, 4, 4, 4, 3, 4, 4,\n",
       "       4, 3, 3, 3, 4, 3, 4, 4, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4,\n",
       "       4, 4, 4, 2, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 2, 3, 4, 4,\n",
       "       3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 4, 4, 3, 3,\n",
       "       4, 4, 4, 4, 4, 3, 2, 4, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4,\n",
       "       3, 3, 3, 4, 4, 3, 4, 4, 3, 4, 3, 4, 4, 4, 3, 2, 2, 2, 3, 3, 4, 3,\n",
       "       3, 3, 4, 4, 4, 3, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 4, 4, 2, 3, 4, 3,\n",
       "       3, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 4, 4, 3, 4,\n",
       "       4, 4, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 4, 4, 4, 4, 3,\n",
       "       4, 4, 4, 3, 4, 4, 4, 3, 4, 3, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3,\n",
       "       2, 2, 4, 4, 4, 4, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 4, 4, 4, 4, 4,\n",
       "       3, 4, 3, 4, 4, 3, 3, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
       "       4, 4, 4, 3], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, 2, 3, 4, 4, 4, 2, 4, 4, 3, 4, 3, 3, 4, 3, 4, 4, 4, 3, 3,\n",
       "       3, 3, 3, 4, 4, 4, 3, 4, 4, 3, 3, 4, 4, 3, 4, 4, 3, 3, 4, 2, 3, 3,\n",
       "       3, 3, 3, 3, 2, 3, 4, 3, 4, 4, 4, 4, 4, 3, 3, 4, 3, 4, 3, 3, 4, 4,\n",
       "       4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 4, 4, 3, 4, 3, 4, 3, 3, 4, 3, 2,\n",
       "       4, 4, 3, 4, 3, 3, 1, 3, 3, 4, 3, 2, 4, 3, 3, 4, 4, 2, 4, 4, 4, 4,\n",
       "       2, 3, 3, 4, 3, 4, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4,\n",
       "       4, 3, 4, 3, 3, 4, 4, 3, 4, 4, 4, 3, 3, 3, 3, 3, 4, 4, 4, 3, 4, 4,\n",
       "       4, 3, 3, 3, 4, 3, 4, 4, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4,\n",
       "       4, 4, 4, 2, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 2, 3, 4, 4,\n",
       "       3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 4, 4, 3, 3,\n",
       "       4, 4, 4, 4, 4, 3, 2, 4, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4,\n",
       "       3, 3, 3, 4, 4, 3, 4, 4, 3, 4, 3, 4, 4, 4, 3, 2, 2, 2, 3, 3, 4, 3,\n",
       "       3, 3, 4, 4, 4, 3, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 4, 4, 2, 3, 4, 3,\n",
       "       3, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 4, 4, 3, 4,\n",
       "       4, 4, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 4, 4, 4, 4, 3,\n",
       "       4, 4, 4, 3, 4, 4, 4, 3, 4, 3, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3,\n",
       "       2, 2, 4, 4, 4, 4, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 4, 4, 4, 4, 4,\n",
       "       3, 4, 3, 4, 4, 3, 3, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
       "       4, 4, 4, 3], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f0b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 3, 2, 3, 4, 4, 4, 2, 4, 5, 3, 6, 4, 4, 5, 3, 3, 4, 4, 2, 3,\n",
       "       4, 2, 3, 4, 4, 4, 3, 4, 3, 3, 3, 4, 5, 3, 3, 4, 3, 4, 3, 2, 4, 3,\n",
       "       3, 3, 3, 3, 2, 3, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 5, 4,\n",
       "       4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 3, 4, 3, 3,\n",
       "       4, 3, 3, 4, 3, 3, 2, 3, 3, 4, 3, 2, 4, 3, 3, 4, 4, 3, 4, 4, 3, 4,\n",
       "       2, 3, 2, 3, 4, 4, 3, 4, 3, 3, 3, 3, 4, 5, 3, 3, 4, 3, 4, 4, 5, 4,\n",
       "       3, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 2, 3, 3, 4, 4, 4, 3, 4, 4,\n",
       "       4, 2, 2, 3, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4,\n",
       "       3, 4, 4, 2, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 2, 4, 3, 3, 1, 3, 4, 4,\n",
       "       3, 4, 3, 3, 3, 3, 5, 4, 4, 3, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3,\n",
       "       4, 5, 4, 4, 4, 4, 2, 4, 3, 3, 3, 3, 5, 3, 4, 4, 3, 4, 4, 4, 5, 4,\n",
       "       2, 4, 3, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4, 3, 2, 1, 2, 3, 4, 3, 4, 2,\n",
       "       3, 4, 4, 3, 5, 3, 3, 4, 2, 4, 3, 3, 3, 4, 4, 3, 5, 4, 2, 3, 4, 3,\n",
       "       3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 3, 4, 5, 3, 4, 4, 3, 4, 5, 4, 3, 3,\n",
       "       3, 4, 3, 3, 4, 3, 5, 4, 4, 2, 4, 3, 4, 4, 3, 3, 3, 3, 4, 5, 3, 3,\n",
       "       4, 4, 3, 4, 3, 3, 4, 3, 4, 2, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3,\n",
       "       2, 2, 5, 4, 4, 4, 4, 4, 3, 5, 3, 3, 2, 4, 3, 3, 3, 4, 4, 3, 3, 4,\n",
       "       4, 5, 3, 3, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 3, 3, 4, 4, 3, 4,\n",
       "       4, 4, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([4, 4, 3, 2, 3, 4, 4, 4, 2, 4, 5, 3, 6, 4, 4, 5, 3, 3, 4, 4, 2, 3,\n",
       "       4, 2, 3, 4, 4, 4, 3, 4, 3, 3, 3, 4, 5, 3, 3, 4, 3, 4, 3, 2, 4, 3,\n",
       "       3, 3, 3, 3, 2, 3, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 5, 4,\n",
       "       4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 3, 4, 3, 3,\n",
       "       4, 3, 3, 4, 3, 3, 2, 3, 3, 4, 3, 2, 4, 3, 3, 4, 4, 3, 4, 4, 3, 4,\n",
       "       2, 3, 2, 3, 4, 4, 3, 4, 3, 3, 3, 3, 4, 5, 3, 3, 4, 3, 4, 4, 5, 4,\n",
       "       3, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 2, 3, 3, 4, 4, 4, 3, 4, 4,\n",
       "       4, 2, 2, 3, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4,\n",
       "       3, 4, 4, 2, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 2, 4, 3, 3, 1, 3, 4, 4,\n",
       "       3, 4, 3, 3, 3, 3, 5, 4, 4, 3, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3,\n",
       "       4, 5, 4, 4, 4, 4, 2, 4, 3, 3, 3, 3, 5, 3, 4, 4, 3, 4, 4, 4, 5, 4,\n",
       "       2, 4, 3, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4, 3, 2, 1, 2, 3, 4, 3, 4, 2,\n",
       "       3, 4, 4, 3, 5, 3, 3, 4, 2, 4, 3, 3, 3, 4, 4, 3, 5, 4, 2, 3, 4, 3,\n",
       "       3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 3, 4, 5, 3, 4, 4, 3, 4, 5, 4, 3, 3,\n",
       "       3, 4, 3, 3, 4, 3, 5, 4, 4, 2, 4, 3, 4, 4, 3, 3, 3, 3, 4, 5, 3, 3,\n",
       "       4, 4, 3, 4, 3, 3, 4, 3, 4, 2, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3,\n",
       "       2, 2, 5, 4, 4, 4, 4, 4, 3, 5, 3, 3, 2, 4, 3, 3, 3, 4, 4, 3, 3, 4,\n",
       "       4, 5, 3, 3, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 3, 3, 4, 4, 3, 4,\n",
       "       4, 4, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac2bb46",
   "metadata": {},
   "source": [
    "#### 3.dii. Displaying the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033213a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee0c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   2,   0,   0,   0,   0],\n",
       "       [  1,  12,  14,   0,   0,   0],\n",
       "       [  0,   3, 125,  41,   0,   0],\n",
       "       [  0,   0,  47, 133,   0,   0],\n",
       "       [  0,   0,   1,  20,   0,   0],\n",
       "       [  0,   0,   0,   1,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   2,   0,   0,   0,   0],\n",
       "       [  1,  12,  14,   0,   0,   0],\n",
       "       [  0,   3, 125,  41,   0,   0],\n",
       "       [  0,   0,  47, 133,   0,   0],\n",
       "       [  0,   0,   1,  20,   0,   0],\n",
       "       [  0,   0,   0,   1,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f72f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe for an array-formatted confusion matrix, so it will be easier to decypher. \n",
    "df = pd.DataFrame(matrix,\n",
    "                    columns = [0,1,2,3,4,5],\n",
    "                    index = [0,1,2,3,4,5]\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7252bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the confusion matrix\n",
    "plt.figure(figsize = (8,7))\n",
    "sns.heatmap(matrix, annot = True)\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Values\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.subplots_adjust(left=5, bottom=5, right=6, top=6, wspace=2, hspace=3)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e398ba",
   "metadata": {},
   "source": [
    "A confusion matrix is used to know the performance of a machine learning classification. It gives us a comparison between Actual and predicted values. It is a matrix in the form of an N x N matrix, where N is the number of classes or outputs.\n",
    "For 4 classes, we get 4 x 4 confusion matrix and so on. The confusion matrix uses 4 terms to find percission, accuracy and etc. These terms are as follows, True Positive (TP), False Positive(FP), True Negative(TN), and False Negative(FN).  \n",
    "\n",
    "Example of said terms based on our matrix is as follows: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e3a01",
   "metadata": {},
   "source": [
    "For class 1,\n",
    "\n",
    "TP: The actual value and predicted value are equal, so TP = 12\n",
    "\n",
    "FN: The sum of values of corresponding rows except the TP value \n",
    "    FN = 15\n",
    "    \n",
    "FP: The sum of values of corresponding columns except for the TP Value\n",
    "    FP = 5\n",
    "    \n",
    "TN: The sum of all columns and rows except the values of that class we are calculating for. \n",
    "    TN = 368\n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN ) = 95%\n",
    "\n",
    "Precision = (TP/(TP+FP)) = 70.59%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ce7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4654ee0",
   "metadata": {},
   "source": [
    "Our accuracy for this model is 67.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80119f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3ec68c2",
   "metadata": {},
   "source": [
    "### 3.diii. Explaining Quadratic Weighted Kappa (QWK) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c4f26",
   "metadata": {},
   "source": [
    "Submissions are scored based on the quadratic weighted kappa, which measures the agreement between two ratings. This metric typically varies from 0 (random agreement between raters) to 1 (complete agreement between raters). In the event that there is less agreement between the raters than expected by chance, the metric may go below 0. The quadratic weighted kappa is calculated between the scores which are expected/known and the predicted scores.\n",
    "\n",
    "Results have 5 possible ratings, 0,1,2,3,4. The quadratic weighted kappa is calculated as follows. First, an N x N histogram matrix O is constructed, such that Oi,j corresponds to the number of adoption records that have a rating of i (actual) and received a predicted rating j. An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted rating scores.\n",
    "\n",
    "An N-by-N histogram matrix of expected ratings, E, is calculated, assuming that there is no correlation between rating scores. This is calculated as the outer product between the actual rating's histogram vector of ratings and the predicted rating's histogram vector of ratings, normalized such that E and O have the same sum.\n",
    "\n",
    "From these three matrices, the quadratic weighted kappa is calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708d233f",
   "metadata": {},
   "source": [
    "### 3.div. Obtaining QWK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c943b",
   "metadata": {},
   "source": [
    "### Weighted Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b346d8",
   "metadata": {},
   "source": [
    "An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted rating scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3053e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.zeros((6,6)); w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94383ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        w[i][j] = float(((i-j)**2)/16) #as per formula, for this competition, N=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee731c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.0625, 0.25  , 0.5625, 1.    , 1.5625],\n",
       "       [0.0625, 0.    , 0.0625, 0.25  , 0.5625, 1.    ],\n",
       "       [0.25  , 0.0625, 0.    , 0.0625, 0.25  , 0.5625],\n",
       "       [0.5625, 0.25  , 0.0625, 0.    , 0.0625, 0.25  ],\n",
       "       [1.    , 0.5625, 0.25  , 0.0625, 0.    , 0.0625],\n",
       "       [1.5625, 1.    , 0.5625, 0.25  , 0.0625, 0.    ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.0625, 0.25  , 0.5625, 1.    , 1.5625],\n",
       "       [0.0625, 0.    , 0.0625, 0.25  , 0.5625, 1.    ],\n",
       "       [0.25  , 0.0625, 0.    , 0.0625, 0.25  , 0.5625],\n",
       "       [0.5625, 0.25  , 0.0625, 0.    , 0.0625, 0.25  ],\n",
       "       [1.    , 0.5625, 0.25  , 0.0625, 0.    , 0.0625],\n",
       "       [1.5625, 1.    , 0.5625, 0.25  , 0.0625, 0.    ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f79505d",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e54e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=400\n",
    "act_hist=np.zeros([N])\n",
    "for item in y_test: \n",
    "    act_hist[item]+=1\n",
    "    \n",
    "pred_hist=np.zeros([N])\n",
    "for item in y_pred: \n",
    "    pred_hist[item]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e1c3c2",
   "metadata": {},
   "source": [
    "print(f'Actuals value counts:{act_hist},\\n Prediction value counts:{pred_hist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b84b0",
   "metadata": {},
   "source": [
    "### Expected Value (Outer product of histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5dae7",
   "metadata": {},
   "source": [
    "Expected matrix is calculated as the outer product between the actual rating's histogram vector of ratings and the predicted rating's histogram vector of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0524e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   2.,  34., ...,   0.,   0.,   0.],\n",
       "       [  0.,  27., 459., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   2.,  34., ...,   0.,   0.,   0.],\n",
       "       [  0.,  27., 459., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = np.outer(act_hist, pred_hist); E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a762a24",
   "metadata": {},
   "source": [
    "### Normalise E and O matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d76c8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = E/E.sum(); E.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9132f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = matrix/matrix.sum(); matrix.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df473e5",
   "metadata": {},
   "source": [
    "### Calculate Weighted Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3276e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6073676309255731"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6073676309255731"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=0\n",
    "den=0\n",
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        num+=w[i][j]*matrix[i][j]\n",
    "        den+=w[i][j]*E[i][j]\n",
    " \n",
    "weighted_kappa = (1 - (num/den)); weighted_kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f384fb59",
   "metadata": {},
   "source": [
    "A negative QWK score implies that the model is \"worse than random\". A random model should give a score of close to 0. Lastly, perfect predictions will yield a score of 1. Therefore our score of 0.6 is about 60% towards perfect predictions. which means more or less 40% of the time we will be getting a false prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a6284",
   "metadata": {},
   "source": [
    "## Using the inbuilt method in sklearn to calculate QWK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52fd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.615036231884058"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.615036231884058"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cks(y_pred, y_test, labels= None, weights = 'quadratic', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76fbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4bb730e",
   "metadata": {},
   "source": [
    "## Kaggle Submission prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('FIT1043-Essay-Features-Submission.csv') #reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64e9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1623</td>\n",
       "      <td>4332</td>\n",
       "      <td>900</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4.813333</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>893.988852</td>\n",
       "      <td>0.993321</td>\n",
       "      <td>392</td>\n",
       "      <td>0.435556</td>\n",
       "      <td>196</td>\n",
       "      <td>0.217778</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1143</td>\n",
       "      <td>1465</td>\n",
       "      <td>280</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.232143</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>278.321343</td>\n",
       "      <td>0.994005</td>\n",
       "      <td>131</td>\n",
       "      <td>0.467857</td>\n",
       "      <td>51</td>\n",
       "      <td>0.182143</td>\n",
       "      <td>339</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660</td>\n",
       "      <td>1696</td>\n",
       "      <td>325</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.218462</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>17.105263</td>\n",
       "      <td>321.316770</td>\n",
       "      <td>0.988667</td>\n",
       "      <td>178</td>\n",
       "      <td>0.547692</td>\n",
       "      <td>92</td>\n",
       "      <td>0.283077</td>\n",
       "      <td>352</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1596</td>\n",
       "      <td>2640</td>\n",
       "      <td>555</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4.756757</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>19.821429</td>\n",
       "      <td>551.989150</td>\n",
       "      <td>0.994575</td>\n",
       "      <td>228</td>\n",
       "      <td>0.410811</td>\n",
       "      <td>107</td>\n",
       "      <td>0.192793</td>\n",
       "      <td>632</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>846</td>\n",
       "      <td>2844</td>\n",
       "      <td>596</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.771812</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>24.833333</td>\n",
       "      <td>593.658810</td>\n",
       "      <td>0.996072</td>\n",
       "      <td>279</td>\n",
       "      <td>0.468121</td>\n",
       "      <td>138</td>\n",
       "      <td>0.231544</td>\n",
       "      <td>626</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essayid  chars  words  commas  apostrophes  punctuations  avg_word_length  \\\n",
       "0     1623   4332    900      28           13             0         4.813333   \n",
       "1     1143   1465    280      11            3             1         5.232143   \n",
       "2      660   1696    325      17            2             0         5.218462   \n",
       "3     1596   2640    555      20           17             0         4.756757   \n",
       "4      846   2844    596      33            4             1         4.771812   \n",
       "\n",
       "   sentences  questions  avg_word_sentence         POS  POS/total_words  \\\n",
       "0         39          1          23.076923  893.988852         0.993321   \n",
       "1         14          3          20.000000  278.321343         0.994005   \n",
       "2         19          1          17.105263  321.316770         0.988667   \n",
       "3         28          0          19.821429  551.989150         0.994575   \n",
       "4         24          9          24.833333  593.658810         0.996072   \n",
       "\n",
       "   prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0           392                  0.435556            196   \n",
       "1           131                  0.467857             51   \n",
       "2           178                  0.547692             92   \n",
       "3           228                  0.410811            107   \n",
       "4           279                  0.468121            138   \n",
       "\n",
       "   synonym_words/total_words  unstemmed  stemmed  \n",
       "0                   0.217778        750      750  \n",
       "1                   0.182143        339      316  \n",
       "2                   0.283077        352      337  \n",
       "3                   0.192793        632      605  \n",
       "4                   0.231544        626      607  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1623</td>\n",
       "      <td>4332</td>\n",
       "      <td>900</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4.813333</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>893.988852</td>\n",
       "      <td>0.993321</td>\n",
       "      <td>392</td>\n",
       "      <td>0.435556</td>\n",
       "      <td>196</td>\n",
       "      <td>0.217778</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1143</td>\n",
       "      <td>1465</td>\n",
       "      <td>280</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.232143</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>278.321343</td>\n",
       "      <td>0.994005</td>\n",
       "      <td>131</td>\n",
       "      <td>0.467857</td>\n",
       "      <td>51</td>\n",
       "      <td>0.182143</td>\n",
       "      <td>339</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660</td>\n",
       "      <td>1696</td>\n",
       "      <td>325</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.218462</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>17.105263</td>\n",
       "      <td>321.316770</td>\n",
       "      <td>0.988667</td>\n",
       "      <td>178</td>\n",
       "      <td>0.547692</td>\n",
       "      <td>92</td>\n",
       "      <td>0.283077</td>\n",
       "      <td>352</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1596</td>\n",
       "      <td>2640</td>\n",
       "      <td>555</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4.756757</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>19.821429</td>\n",
       "      <td>551.989150</td>\n",
       "      <td>0.994575</td>\n",
       "      <td>228</td>\n",
       "      <td>0.410811</td>\n",
       "      <td>107</td>\n",
       "      <td>0.192793</td>\n",
       "      <td>632</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>846</td>\n",
       "      <td>2844</td>\n",
       "      <td>596</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.771812</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>24.833333</td>\n",
       "      <td>593.658810</td>\n",
       "      <td>0.996072</td>\n",
       "      <td>279</td>\n",
       "      <td>0.468121</td>\n",
       "      <td>138</td>\n",
       "      <td>0.231544</td>\n",
       "      <td>626</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essayid  chars  words  commas  apostrophes  punctuations  avg_word_length  \\\n",
       "0     1623   4332    900      28           13             0         4.813333   \n",
       "1     1143   1465    280      11            3             1         5.232143   \n",
       "2      660   1696    325      17            2             0         5.218462   \n",
       "3     1596   2640    555      20           17             0         4.756757   \n",
       "4      846   2844    596      33            4             1         4.771812   \n",
       "\n",
       "   sentences  questions  avg_word_sentence         POS  POS/total_words  \\\n",
       "0         39          1          23.076923  893.988852         0.993321   \n",
       "1         14          3          20.000000  278.321343         0.994005   \n",
       "2         19          1          17.105263  321.316770         0.988667   \n",
       "3         28          0          19.821429  551.989150         0.994575   \n",
       "4         24          9          24.833333  593.658810         0.996072   \n",
       "\n",
       "   prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0           392                  0.435556            196   \n",
       "1           131                  0.467857             51   \n",
       "2           178                  0.547692             92   \n",
       "3           228                  0.410811            107   \n",
       "4           279                  0.468121            138   \n",
       "\n",
       "   synonym_words/total_words  unstemmed  stemmed  \n",
       "0                   0.217778        750      750  \n",
       "1                   0.182143        339      316  \n",
       "2                   0.283077        352      337  \n",
       "3                   0.192793        632      605  \n",
       "4                   0.231544        626      607  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head() #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965bd975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1226</td>\n",
       "      <td>1208</td>\n",
       "      <td>242</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.991736</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>18.615385</td>\n",
       "      <td>237.327684</td>\n",
       "      <td>0.980693</td>\n",
       "      <td>135</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>58</td>\n",
       "      <td>0.239669</td>\n",
       "      <td>244</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>862</td>\n",
       "      <td>4039</td>\n",
       "      <td>817</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4.943696</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>17.382979</td>\n",
       "      <td>812.656033</td>\n",
       "      <td>0.994683</td>\n",
       "      <td>386</td>\n",
       "      <td>0.472460</td>\n",
       "      <td>210</td>\n",
       "      <td>0.257038</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1562</td>\n",
       "      <td>2448</td>\n",
       "      <td>468</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.230769</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>21.272727</td>\n",
       "      <td>465.656652</td>\n",
       "      <td>0.994993</td>\n",
       "      <td>224</td>\n",
       "      <td>0.478632</td>\n",
       "      <td>101</td>\n",
       "      <td>0.215812</td>\n",
       "      <td>540</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1336</td>\n",
       "      <td>1081</td>\n",
       "      <td>214</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.051402</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>19.454545</td>\n",
       "      <td>212.990566</td>\n",
       "      <td>0.995283</td>\n",
       "      <td>114</td>\n",
       "      <td>0.532710</td>\n",
       "      <td>63</td>\n",
       "      <td>0.294393</td>\n",
       "      <td>259</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1171</td>\n",
       "      <td>2094</td>\n",
       "      <td>433</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4.836028</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>22.789474</td>\n",
       "      <td>426.651090</td>\n",
       "      <td>0.985337</td>\n",
       "      <td>221</td>\n",
       "      <td>0.510393</td>\n",
       "      <td>121</td>\n",
       "      <td>0.279446</td>\n",
       "      <td>501</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     essayid  chars  words  commas  apostrophes  punctuations  \\\n",
       "194     1226   1208    242       8            8             0   \n",
       "195      862   4039    817      24           11             1   \n",
       "196     1562   2448    468      22            7             0   \n",
       "197     1336   1081    214      14            5             0   \n",
       "198     1171   2094    433      11           12             0   \n",
       "\n",
       "     avg_word_length  sentences  questions  avg_word_sentence         POS  \\\n",
       "194         4.991736         13          0          18.615385  237.327684   \n",
       "195         4.943696         47          2          17.382979  812.656033   \n",
       "196         5.230769         22          0          21.272727  465.656652   \n",
       "197         5.051402         11          0          19.454545  212.990566   \n",
       "198         4.836028         19          0          22.789474  426.651090   \n",
       "\n",
       "     POS/total_words  prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "194         0.980693           135                  0.557851             58   \n",
       "195         0.994683           386                  0.472460            210   \n",
       "196         0.994993           224                  0.478632            101   \n",
       "197         0.995283           114                  0.532710             63   \n",
       "198         0.985337           221                  0.510393            121   \n",
       "\n",
       "     synonym_words/total_words  unstemmed  stemmed  \n",
       "194                   0.239669        244      242  \n",
       "195                   0.257038        750      750  \n",
       "196                   0.215812        540      526  \n",
       "197                   0.294393        259      256  \n",
       "198                   0.279446        501      478  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1226</td>\n",
       "      <td>1208</td>\n",
       "      <td>242</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.991736</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>18.615385</td>\n",
       "      <td>237.327684</td>\n",
       "      <td>0.980693</td>\n",
       "      <td>135</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>58</td>\n",
       "      <td>0.239669</td>\n",
       "      <td>244</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>862</td>\n",
       "      <td>4039</td>\n",
       "      <td>817</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4.943696</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>17.382979</td>\n",
       "      <td>812.656033</td>\n",
       "      <td>0.994683</td>\n",
       "      <td>386</td>\n",
       "      <td>0.472460</td>\n",
       "      <td>210</td>\n",
       "      <td>0.257038</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1562</td>\n",
       "      <td>2448</td>\n",
       "      <td>468</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.230769</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>21.272727</td>\n",
       "      <td>465.656652</td>\n",
       "      <td>0.994993</td>\n",
       "      <td>224</td>\n",
       "      <td>0.478632</td>\n",
       "      <td>101</td>\n",
       "      <td>0.215812</td>\n",
       "      <td>540</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1336</td>\n",
       "      <td>1081</td>\n",
       "      <td>214</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.051402</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>19.454545</td>\n",
       "      <td>212.990566</td>\n",
       "      <td>0.995283</td>\n",
       "      <td>114</td>\n",
       "      <td>0.532710</td>\n",
       "      <td>63</td>\n",
       "      <td>0.294393</td>\n",
       "      <td>259</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1171</td>\n",
       "      <td>2094</td>\n",
       "      <td>433</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4.836028</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>22.789474</td>\n",
       "      <td>426.651090</td>\n",
       "      <td>0.985337</td>\n",
       "      <td>221</td>\n",
       "      <td>0.510393</td>\n",
       "      <td>121</td>\n",
       "      <td>0.279446</td>\n",
       "      <td>501</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     essayid  chars  words  commas  apostrophes  punctuations  \\\n",
       "194     1226   1208    242       8            8             0   \n",
       "195      862   4039    817      24           11             1   \n",
       "196     1562   2448    468      22            7             0   \n",
       "197     1336   1081    214      14            5             0   \n",
       "198     1171   2094    433      11           12             0   \n",
       "\n",
       "     avg_word_length  sentences  questions  avg_word_sentence         POS  \\\n",
       "194         4.991736         13          0          18.615385  237.327684   \n",
       "195         4.943696         47          2          17.382979  812.656033   \n",
       "196         5.230769         22          0          21.272727  465.656652   \n",
       "197         5.051402         11          0          19.454545  212.990566   \n",
       "198         4.836028         19          0          22.789474  426.651090   \n",
       "\n",
       "     POS/total_words  prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "194         0.980693           135                  0.557851             58   \n",
       "195         0.994683           386                  0.472460            210   \n",
       "196         0.994993           224                  0.478632            101   \n",
       "197         0.995283           114                  0.532710             63   \n",
       "198         0.985337           221                  0.510393            121   \n",
       "\n",
       "     synonym_words/total_words  unstemmed  stemmed  \n",
       "194                   0.239669        244      242  \n",
       "195                   0.257038        750      750  \n",
       "196                   0.215812        540      526  \n",
       "197                   0.294393        259      256  \n",
       "198                   0.279446        501      478  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.tail() #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d6bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = submission.iloc[:,np.r_[1:5,7:9,13:18]].values #feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb59169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features\n",
    "scale = StandardScaler()\n",
    "X = scale.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb92002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2189"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2189"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trained = clf.predict(X) #training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7053a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trained.size \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'essayid':submission[\"essayid\"],'score': X_trained})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d90d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame = my_submission.to_csv('32633122-JoshuaLimBoonHor-1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d096548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "864176a5",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f7620e",
   "metadata": {},
   "source": [
    "Based on all the data we have trained and tested in part 3, we can tell that the accuracy of the trained model is only about 60. Therefore, we can conclude that a better model must be suggested as 60% is not a liable enough model to be used.\n",
    "Changing the features taken into account may result in better accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
